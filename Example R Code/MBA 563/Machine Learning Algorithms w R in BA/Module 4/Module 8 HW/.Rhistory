v4*v1
install.packages("swirl")
library("swirl")
rm(list=ls())
library("swirl")
swirl()
5_+7
5+7
x <- 5+7
x
y <- x-3
y
c(1.1,9,3.14)
z <- c(1.1,9,3.14)
?c
z
c(z,555,z)
z*2+100
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z / my_sqrt
my_div
c(1,2,3,4) + c(0,10)
c(1,2,3,4) + c(0,10,100)
z*2+1000
my_div
swirl
swirl()
builtins()
995
?attr
attr(x,"dim") <- c(2,5)
x <- 1:10
attr(x,"dim") <- c(2,5)
x
plot(1:10)
for (x in 1:10){
print(x)
}
for (x in 1:10){
print(x)
}
for (x in 1:10){
print(x+1)
}
for (x in fruits) {
print(x)
}
fruits <- list("apple", "banana", "cherry")
for (x in fruits) {
print(x)
}
fruits <- list("apple", "banana", "cherry")
for (x in fruits) {
print(x)
}
dice <- c(1,2,3,4,5,6)
for (x in dice){
print(x)
}
if (!require("devtools"))
install.packages("devtools")
devtools::install_github("shiny", "rstudio")
install.packages("shiny")
dir.exists("/Library/Frameworks/R.framework/Versions/3.3/Resources/library/00LOCK-jrosen48-prcr-4f6f783") returns FALSE?
dir.exists("/Library/Frameworks/R.framework/Versions/3.3/Resources/library/00LOCK-jrosen48-prcr-4f6f783") returns FALSE
rm -rf /Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv
:$ rm -rf /Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv
$ rm -rf /Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv
rm -rf /Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv
rm /Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv
dir.exists("/Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv")
rm -rf /Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv
R CMD INSTALL --no-lock <pkg>
install.packages("Rcpp", dependencies=TRUE, INSTALL_opts = c('--no-lock'))
install.packages(xxx, INSTALL_opts = c('--no-lock'))
install.packages(/Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv), INSTALL_opts = c('--no-lock'))
devtools::install_github("rstudio/httpuv")
install.packages("Shiny", dependencies = TRUE, INSTALL_opts = '--no-lock')
install.packages("shiny", dependencies = TRUE, INSTALL_opts = '--no-lock')
unlink("/Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv", recursive = TRUE)
install.packages("httpuv")
install.packages("shiny", dependencies = TRUE, INSTALL_opts = '--no-lock')
install.packages(c("Rcpp", "httpuv", "shiny"))
dir.exists(/Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv)
dir.exists(Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv)
dir.exists("Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv")
rm -rg /Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv
rm -rg "/Library/Frameworks/R.framework/Versions/4.0/Resources/library/00LOCK-httpuv"
library(shiny)
setwd("~/Documents/iMBA Classes/MBA 563/MOOC2 Machine Learning Algorithms w R in BA/Module 8 Mini Assignment")
setwd("~/Documents/iMBA Classes/MBA 563/MOOC2 Machine Learning Algorithms w R in BA/Module 4/Module 8 MA")
library(tidyverse)
library(ggplot2)
df <- read.csv("default of credit card clients.csv")
my_confusion_matrix <- function(cf_table) {
true_positive <- cf_table[4]
true_negative <- cf_table[1]
false_positive <- cf_table[2]
false_negative <- cf_table[3]
accuracy <- (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)
sensitivity_recall <- true_positive / (true_positive + false_negative)
specificity_selectivity <- true_negative / (true_negative + false_positive)
precision <- true_positive / (true_positive + false_positive)
neg_pred_value <- true_negative/(true_negative + false_negative)
print(cf_table)
my_list <- list(sprintf("%1.0f = True Positive (TP), Hit", true_positive),
sprintf("%1.0f = True Negative (TN), Rejection", true_negative),
sprintf("%1.0f = False Positive (FP), Type 1 Error", false_positive),
sprintf("%1.0f = False Negative (FN), Type 2 Error", false_negative),
sprintf("%1.4f = Accuracy (TP+TN/(TP+TN+FP+FN))", accuracy),
sprintf("%1.4f = Sensitivity, Recall, Hit Rate, True Positive Rate (How many positives did the model get right? TP/(TP+FN))", sensitivity_recall),
sprintf("%1.4f = Specificity, Selectivity, True Negative Rate (How many negatives did the model get right? TN/(TN+FP))", specificity_selectivity),
sprintf("%1.4f = Precision, Positive Predictive Value (How good are the model's positive predictions? TP/(TP+FP))", precision),
sprintf("%1.4f = Negative Predictive Value (How good are the model's negative predictions? TN/(TN+FN)", neg_pred_value)
)
return(my_list)
}
colnames(df) <- as.character(unlist(df[1,]))
df = df[-1, ]
head(df)
colnames(df)[colnames(df)=="default payment next month"] <- "default_payment"
head(df)
df[, 1:25] <- sapply(df[, 1:25], as.numeric)
str(df)
dim(df)
str(df)
summary(df)
# Update EDUCATION Category 0,5,6 to Category 4 (others)
# (1 = graduate school; 2 = university; 3 = high school; 4 = others)
count(df, vars = EDUCATION)
df$EDUCATION[df$EDUCATION == 0] <- 4
df$EDUCATION[df$EDUCATION == 5] <- 4
df$EDUCATION[df$EDUCATION == 6] <- 4
# Update MARRIAGE Category 0 to Category 3 (others)
# (1 = married; 2 = single; 3 = others)
count(df, vars = MARRIAGE)
df$MARRIAGE[df$MARRIAGE == 0] <- 3
corrplot(cor(df)
, method = 'color'      # Visualization method for the correlation matrix
, order = 'hclust'      # Orders the variables so that ones that behave similarly are placed next to each other
, addCoef.col = 'black' # Color of coefficients on the graph
, number.cex = .3       # Lower values decrease the size of the numbers in the cells
)
df <- read.csv("default of credit card clients.csv")
library(tidyverse)
library(ggplot2)
df <- read.csv("default of credit card clients.csv")
my_confusion_matrix <- function(cf_table) {
true_positive <- cf_table[4]
true_negative <- cf_table[1]
false_positive <- cf_table[2]
false_negative <- cf_table[3]
accuracy <- (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)
sensitivity_recall <- true_positive / (true_positive + false_negative)
specificity_selectivity <- true_negative / (true_negative + false_positive)
precision <- true_positive / (true_positive + false_positive)
neg_pred_value <- true_negative/(true_negative + false_negative)
print(cf_table)
my_list <- list(sprintf("%1.0f = True Positive (TP), Hit", true_positive),
sprintf("%1.0f = True Negative (TN), Rejection", true_negative),
sprintf("%1.0f = False Positive (FP), Type 1 Error", false_positive),
sprintf("%1.0f = False Negative (FN), Type 2 Error", false_negative),
sprintf("%1.4f = Accuracy (TP+TN/(TP+TN+FP+FN))", accuracy),
sprintf("%1.4f = Sensitivity, Recall, Hit Rate, True Positive Rate (How many positives did the model get right? TP/(TP+FN))", sensitivity_recall),
sprintf("%1.4f = Specificity, Selectivity, True Negative Rate (How many negatives did the model get right? TN/(TN+FP))", specificity_selectivity),
sprintf("%1.4f = Precision, Positive Predictive Value (How good are the model's positive predictions? TP/(TP+FP))", precision),
sprintf("%1.4f = Negative Predictive Value (How good are the model's negative predictions? TN/(TN+FN)", neg_pred_value)
)
return(my_list)
}
colnames(df) <- as.character(unlist(df[1,]))
df = df[-1, ]
head(df)
colnames(df)[colnames(df)=="default payment next month"] <- "default_payment"
head(df)
df[, 1:25] <- sapply(df[, 1:25], as.numeric)
str(df)
dim(df)
str(df)
summary(df)
# Update EDUCATION Category 0,5,6 to Category 4 (others)
# (1 = graduate school; 2 = university; 3 = high school; 4 = others)
count(df, vars = EDUCATION)
df$EDUCATION[df$EDUCATION == 0] <- 4
df$EDUCATION[df$EDUCATION == 5] <- 4
df$EDUCATION[df$EDUCATION == 6] <- 4
# Update MARRIAGE Category 0 to Category 3 (others)
# (1 = married; 2 = single; 3 = others)
count(df, vars = MARRIAGE)
df$MARRIAGE[df$MARRIAGE == 0] <- 3
corrplot(cor(df)
, method = 'color'      # Visualization method for the correlation matrix
, order = 'hclust'      # Orders the variables so that ones that behave similarly are placed next to each other
, addCoef.col = 'black' # Color of coefficients on the graph
, number.cex = .3       # Lower values decrease the size of the numbers in the cells
)
library(corrplot)
library(corrplot)
library(tidyverse)
library(ggplot2)
library(corrplot)
df <- read.csv("default of credit card clients.csv")
my_confusion_matrix <- function(cf_table) {
true_positive <- cf_table[4]
true_negative <- cf_table[1]
false_positive <- cf_table[2]
false_negative <- cf_table[3]
accuracy <- (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)
sensitivity_recall <- true_positive / (true_positive + false_negative)
specificity_selectivity <- true_negative / (true_negative + false_positive)
precision <- true_positive / (true_positive + false_positive)
neg_pred_value <- true_negative/(true_negative + false_negative)
print(cf_table)
my_list <- list(sprintf("%1.0f = True Positive (TP), Hit", true_positive),
sprintf("%1.0f = True Negative (TN), Rejection", true_negative),
sprintf("%1.0f = False Positive (FP), Type 1 Error", false_positive),
sprintf("%1.0f = False Negative (FN), Type 2 Error", false_negative),
sprintf("%1.4f = Accuracy (TP+TN/(TP+TN+FP+FN))", accuracy),
sprintf("%1.4f = Sensitivity, Recall, Hit Rate, True Positive Rate (How many positives did the model get right? TP/(TP+FN))", sensitivity_recall),
sprintf("%1.4f = Specificity, Selectivity, True Negative Rate (How many negatives did the model get right? TN/(TN+FP))", specificity_selectivity),
sprintf("%1.4f = Precision, Positive Predictive Value (How good are the model's positive predictions? TP/(TP+FP))", precision),
sprintf("%1.4f = Negative Predictive Value (How good are the model's negative predictions? TN/(TN+FN)", neg_pred_value)
)
return(my_list)
}
colnames(df) <- as.character(unlist(df[1,]))
df = df[-1, ]
head(df)
colnames(df)[colnames(df)=="default payment next month"] <- "default_payment"
head(df)
df[, 1:25] <- sapply(df[, 1:25], as.numeric)
str(df)
dim(df)
str(df)
summary(df)
# Update EDUCATION Category 0,5,6 to Category 4 (others)
# (1 = graduate school; 2 = university; 3 = high school; 4 = others)
count(df, vars = EDUCATION)
df$EDUCATION[df$EDUCATION == 0] <- 4
df$EDUCATION[df$EDUCATION == 5] <- 4
df$EDUCATION[df$EDUCATION == 6] <- 4
# Update MARRIAGE Category 0 to Category 3 (others)
# (1 = married; 2 = single; 3 = others)
count(df, vars = MARRIAGE)
df$MARRIAGE[df$MARRIAGE == 0] <- 3
corrplot(cor(df)
, method = 'color'      # Visualization method for the correlation matrix
, order = 'hclust'      # Orders the variables so that ones that behave similarly are placed next to each other
, addCoef.col = 'black' # Color of coefficients on the graph
, number.cex = .3       # Lower values decrease the size of the numbers in the cells
)
df_new <- select(df,-ID,-BILL_AMT1,-BILL_AMT2,-BILL_AMT3,-BILL_AMT4,-BILL_AMT5,-BILL_AMT6)
head(df_new)
df_new[,1:17] <- scale(df_new[, 1:17])
head(df_new)
contrasts(factor(df_new$default_payment))
library(caret)
set.seed(77)
partition <- caret::createDataPartition(y=df_new$default_payment, p=.70, list=FALSE)
data_train <- df_new[partition,]
data_test <- df_new[-partition,]
print(nrow(data_train)/(nrow(data_test)+nrow(data_train)))
dim(data_train)
dim(data_test)
model_train <- glm(default_payment ~ ., family=binomial, data=data_train)
summary(model_train)
predict_train <- predict(model_train, newdata=data_train, type='response')
print(summary(predict_train))
data_train$prediction <- predict_train
head(data_train, n=10)
table1 <- table(predict_train>0.5, data_train$default_payment) #prediction on left and truth on top
my_confusion_matrix(table1)
predict_test <- predict(model_train, newdata=data_test, type='response')
print(summary(predict_test))
data_test$prediction <- predict_test
head(data_test, n=10)
table2 <- table(predict_test>.5, data_test$default_payment) #prediction on left and truth on top
my_confusion_matrix(table2)
setwd("~/Documents/iMBA Classes/MBA 563/MOOC2 Machine Learning Algorithms w R in BA/Module 4/Module 8 Live Session")
library(tidyverse)
#install.packages('factoextra') #only install once
library(factoextra)
#install.packages('tidyverse') #only install once
library(tidyverse)
#install.packages('factoextra') #only install once
library(factoextra)
# read in data (change to your path)
clustering_input1 <- read_rds("clustering_input1.rds")
View(clustering_input1)
clustering_input2 <- clustering_input1 %>%
select(-store)
str(clustering_input2)
summary(clustering_input2)
clustering_input2 <- as.data.frame(scale(clustering_input2))
# Within-cluster sum of square method
set.seed(77)
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "wss")
# Silhouette approach
set.seed(77)
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "silhouette")
set.seed(77)
clusters <- kmeans(clustering_input2, centers=4, iter.max=10, nstart=10)
clusters$size
clusters$centers
fviz_cluster(clusters, clustering_input2,  geom = "point", show.clust.cent = TRUE, palette = "jco", ggtheme = theme_classic())
clustering_input1$cluster <- clusters$cluster
clustering_input1 <- clustering_input1 %>%
mutate(cluster_labels = case_when(
cluster==1 ~ 'Cluster 1',
cluster==2 ~ 'Cluster 2',
cluster==3 ~ 'Cluster 3',
cluster==4 ~ 'Cluster 4'))
slice_sample(clustering_input1, n=10)
#install.packages('dbscan') #only install once
library(dbscan)
# read in data (change to your path)
clustering_input1 <- read_rds("clustering_input1.rds")
# remove store from the data for use later
clustering_input2 <- clustering_input1 %>%
select(-store)
#install.packages('dbscan') #only install once
library(dbscan)
# read in data (change to your path)
clustering_input1 <- read_rds("clustering_input1.rds")
# remove store from the data for use later
clustering_input2 <- clustering_input1 %>%
select(-store)
clustering_input2 <- as.data.frame(scale(clustering_input2))
dbscan::kNNdistplot(clustering_input2, k = 4)
# Draw some lines to find the "elbow"
abline(h = c(2, 3, 4, 5))
set.seed(77)
clusters_db <- dbscan::dbscan(clustering_input2, eps = 3, minPts = 4)
table(clusters_db$cluster)
fviz_cluster(clusters_db, clustering_input2,  geom = "point", show.clust.cent = FALSE, palette = "jco", ggtheme = theme_classic())
setwd("~/Documents/iMBA Classes/MBA 563/MOOC2 Machine Learning Algorithms w R in BA/Module 4/Module 8 HW")
#install.packages('tidyverse') #only install once
library(tidyverse)
#install.packages('factoextra') #only install once
library(factoextra)
# read in data (change to your path)
clustering_input1 <- read_rds("citry.rds")
#install.packages('tidyverse') #only install once
library(tidyverse)
#install.packages('factoextra') #only install once
library(factoextra)
# read in data (change to your path)
clustering_input1 <- read_rds("city.rds")
clustering_input2 <- clustering_input1 %>%
select(-city,-region,-province)
str(clustering_input2)
summary(clustering_input2)
clustering_input2 <- as.data.frame(scale(clustering_input2))
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "wss")
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "silhouette")
unique(clustering_input1$city)
unique(clustering_input1$province)
unique(clustering_input1$region)
set.seed(77)
clusters <- kmeans(clustering_input2, centers=4, iter.max=10, nstart=10)
clusters$size
clusters$centers
fviz_cluster(clusters, clustering_input2,  geom = "point", show.clust.cent = TRUE, palette = "jco", ggtheme = theme_classic())
View(clustering_input1)
clustering_input1$cluster <- clusters$cluster
clustering_input1 <- clustering_input1 %>%
mutate(cluster_labels = case_when(
cluster==1 ~ 'Cluster 1',
cluster==2 ~ 'Cluster 2',
cluster==3 ~ 'Cluster 3',
cluster==4 ~ 'Cluster 4'))
slice_sample(clustering_input1, n=10)
View(clusters)
#install.packages('dbscan') #only install once
library(dbscan)
# read in data (change to your path)
clustering_input1 <- read_rds("city.rds")
#install.packages('dbscan') #only install once
library(dbscan)
# read in data (change to your path)
clustering_input1 <- read_rds("city.rds")
# remove store from the data for use later
clustering_input2 <- clustering_input1 %>%
select(-city,-region,-province)
clustering_input2 <- as.data.frame(scale(clustering_input2))
dbscan::kNNdistplot(clustering_input2, k = 4)
# Draw some lines to find the "elbow"
abline(h = c(2, 3, 4, 5))
set.seed(77)
clusters_db <- dbscan::dbscan(clustering_input2, eps = 3, minPts = 4)
table(clusters_db$cluster)
fviz_cluster(clusters_db, clustering_input2,  geom = "point", show.clust.cent = FALSE, palette = "jco", ggtheme = theme_classic())
#install.packages('tidyverse') #only install once
library(tidyverse)
#install.packages('factoextra') #only install once
library(factoextra)
# read in data (change to your path)
clustering_input1 <- read_rds("city.rds")
clustering_input2 <- clustering_input1 %>%
select(-city,-region,-province)
str(clustering_input2)
summary(clustering_input2)
clustering_input2 <- as.data.frame(scale(clustering_input2))
# Within-cluster sum of square method
set.seed(77)
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "wss")
# Silhouette approach
set.seed(77)
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "silhouette")
set.seed(77)
clusters <- kmeans(clustering_input2, centers=4, iter.max=10, nstart=10)
clusters$size
clusters$centers
fviz_cluster(clusters, clustering_input2,  geom = "point", show.clust.cent = TRUE, palette = "jco", ggtheme = theme_classic())
clustering_input1$cluster <- clusters$cluster
clustering_input1 <- clustering_input1 %>%
mutate(cluster_labels = case_when(
cluster==1 ~ 'Cluster 1',
cluster==2 ~ 'Cluster 2',
cluster==3 ~ 'Cluster 3',
cluster==4 ~ 'Cluster 4'))
slice_sample(clustering_input1, n=10)
#install.packages('dbscan') #only install once
library(dbscan)
# read in data (change to your path)
clustering_input1 <- read_rds("city.rds")
# remove store from the data for use later
clustering_input2 <- clustering_input1 %>%
select(-city,-region,-province)
clustering_input2 <- as.data.frame(scale(clustering_input2))
dbscan::kNNdistplot(clustering_input2, k = 4)
# Draw some lines to find the "elbow"
abline(h = c(2, 3, 4, 5))
set.seed(77)
clusters_db <- dbscan::dbscan(clustering_input2, eps = 3, minPts = 4)
table(clusters_db$cluster)
fviz_cluster(clusters_db, clustering_input2,  geom = "point", show.clust.cent = FALSE, palette = "jco", ggtheme = theme_classic())
#install.packages('tidyverse') #only install once
library(tidyverse)
#install.packages('factoextra') #only install once
library(factoextra)
# read in data (change to your path)
clustering_input1 <- read_rds("city.rds")
clustering_input2 <- clustering_input1 %>%
select(-city,-region,-province)
str(clustering_input2)
summary(clustering_input2)
clustering_input2 <- as.data.frame(scale(clustering_input2))
# Within-cluster sum of square method
set.seed(77)
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "wss")
# Silhouette approach
set.seed(77)
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "silhouette")
View(clustering_input1)
# clusters <- kmeans(clustering_input2, centers=4, iter.max=10, nstart=10)
clusters <- kmeans(clustering_input2, centers=6, iter.max=10, nstart=10)
clusters$size
clusters$centers
fviz_cluster(clusters, clustering_input2,  geom = "point", show.clust.cent = TRUE, palette = "jco", ggtheme = theme_classic())
clusters <- kmeans(clustering_input2, centers=4, iter.max=10, nstart=10)
clusters$size
clusters <- kmeans(clustering_input2, centers=5, iter.max=10, nstart=10)
clusters$size
clusters <- kmeans(clustering_input2, centers=2, iter.max=10, nstart=10)
clusters$size
# clusters <- kmeans(clustering_input2, centers=2, iter.max=10, nstart=10)
clusters <- kmeans(clustering_input2, centers=6, iter.max=10, nstart=10)
clusters$size
View(clustering_input1)
View(clustering_input1)
set.seed(77)
# clusters <- kmeans(clustering_input2, centers=2, iter.max=10, nstart=10)
clusters <- kmeans(clustering_input2, centers=6, iter.max=10, nstart=10)
clusters$size
fviz_cluster(clusters, clustering_input2,  geom = "point", show.clust.cent = TRUE, palette = "jco", ggtheme = theme_classic())
clustering_input1$cluster <- clusters$cluster
clustering_input1 <- clustering_input1 %>%
mutate(cluster_labels = case_when(
cluster==1 ~ 'Small; Low Profit; Isotonic, KingBars',
cluster==2 ~ 'Promo; Regular Bars, Isotonics',
cluster==3 ~ 'Large; High Profit; BagPegCandy; FlatWater',
cluster==4 ~ 'Medium size/profit; Energy',
cluster==5 ~ 'Velocity B Units; BagPegCandy',
cluster==6 ~ 'Small; Low Profit; Gum '))
slice_sample(clustering_input1, n=10)
View(clustering_input1)
set.seed(77)
clusters_db <- dbscan::dbscan(clustering_input2, eps = 5, minPts = 4)
table(clusters_db$cluster)
fviz_cluster(clusters_db, clustering_input2,  geom = "point", show.clust.cent = FALSE, palette = "jco", ggtheme = theme_classic())
dbscan::kNNdistplot(clustering_input2, k = 4)
# Draw some lines to find the "elbow"
abline(h = c(2, 3, 4, 5))
unique(clustering_input1$city)
write.csv(clusters$centers, "clusters.csv")
clusters$centers
clustering_input1$cluster <- clusters$cluster
clustering_input1 <- clustering_input1 %>%
mutate(cluster_labels = case_when(
cluster==1 ~ 'Large/Profitable',
cluster==2 ~ 'Small/Not Profitable',
cluster==3 ~ 'Gum/Flatwater',
cluster==4 ~ 'Medium Size/Medium Profitability',
cluster==5 ~ 'Energy/TakeHomePotato',
cluster==6 ~ 'High Promo Units'))
slice_sample(clustering_input1, n=10)
View(clustering_input1)
# clusters <- kmeans(clustering_input2, centers=2, iter.max=10, nstart=10)
clusters <- kmeans(clustering_input2, centers=6, iter.max=10, nstart=10)
clusters$size
