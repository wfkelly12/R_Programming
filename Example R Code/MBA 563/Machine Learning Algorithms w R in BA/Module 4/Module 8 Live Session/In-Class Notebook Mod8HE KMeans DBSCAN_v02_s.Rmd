************************************************************************
# Title: In-Class Notebook Mod8HE K-Means DBSCAN
Course: MBA563
Term: Summer 2021
Mooc or HE?: HE
Module: 08
Author: William Kelly
************************************************************************

**********K-MEANS ***************************
__1.0 - Load and prep the data__
# Install packages and read in data
```{r}
#install.packages('tidyverse') #only install once
library(tidyverse)
#install.packages('factoextra') #only install once
library(factoextra)

# read in data (change to your path)
clustering_input1 <- read_rds("clustering_input1.rds")
```

# remove store from the data for use later
```{r}
clustering_input2 <- clustering_input1 %>% 
        select(-store)

str(clustering_input2)
summary(clustering_input2)
```

# Z-score standardization
```{r}
clustering_input2 <- as.data.frame(scale(clustering_input2))
```

__2.0 - picking k__
# Find a suitable k using two different methods
```{r}
# Within-cluster sum of square method
set.seed(77)
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "wss")
```

```{r}
# Silhouette approach
set.seed(77)
factoextra::fviz_nbclust(clustering_input2, kmeans, method = "silhouette")
```

__3.0 - Run and evaluate k-means__
# Run the model
```{r}
set.seed(77)
clusters <- kmeans(clustering_input2, centers=4, iter.max=10, nstart=10)
```
Arguments:
* `centers`: number of centroids (k random (distinct) rows are chosen as the initial centers)
* `iter.max`: the maximum number of iterations allowed
* `nstart`: how many random start configurations are chosen (for example, nstart=10 will generate 10 initial random centroids and choose the best one for the algorithm)

# Check the size of the k clusters
(Ideally, clusters are of similar size)
```{r}
clusters$size 
```

# A matrix indicating the mean values for each feature and cluster combination
```{r}
clusters$centers
```

# Visualize the clustering
(Uses principal components to collapse the dimensions of the data down to two dimensions)
```{r}
fviz_cluster(clusters, clustering_input2,  geom = "point", show.clust.cent = TRUE, palette = "jco", ggtheme = theme_classic())
```

__4.0 - put clusters back into the dataset and investigate individual stores__
# Add clusters to the original, un-standardized dataset and add labels
```{r}
clustering_input1$cluster <- clusters$cluster

clustering_input1 <- clustering_input1 %>% 
        mutate(cluster_labels = case_when(
                cluster==1 ~ 'Cluster 1', 
                cluster==2 ~ 'Cluster 2',
                cluster==3 ~ 'Cluster 3',
                cluster==4 ~ 'Cluster 4'))

slice_sample(clustering_input1, n=10)
```



**********DBSCAN**************************************************
__5.0__ 
# Run this code before you start
```{r}
#install.packages('dbscan') #only install once
library(dbscan)

# read in data (change to your path)
clustering_input1 <- read_rds("clustering_input1.rds")

# remove store from the data for use later
clustering_input2 <- clustering_input1 %>% 
        select(-store)
```

# Standardize the data using z-score standardization. 
The features need to be continuous and standardized. Why?
```{r}
clustering_input2 <- as.data.frame(scale(clustering_input2))
```

# The analyst has to pick minPts and epsilon (Ugh!)
# Use `dbscan::knndistplot()` to find a suitable epsilon.
This plots the k-nearest neighbor distances in a matrix of points. It measures the distance to the k nearest neighbors for each plot. K in this case is the minimum points (minPts) and is selected by the analyst. Then, it sorts those by distance, lowest to highest. This is then the x-axis. On the y-axis, the graph plots the distance to the nearest neighbors for each point.
```{r}
dbscan::kNNdistplot(clustering_input2, k = 4)

# Draw some lines to find the "elbow"
abline(h = c(2, 3, 4, 5))
```

# Use the minPts and epsilon from above to run the DBSCAN algorithm
```{r}
set.seed(77)
clusters_db <- dbscan::dbscan(clustering_input2, eps = 3, minPts = 4)
```

# Use the `table()` function to print the size of the clusters.
```{r}
table(clusters_db$cluster)
```

__6.0 - Visualize the clusters__
# Visualize the clusters
```{r}
fviz_cluster(clusters_db, clustering_input2,  geom = "point", show.clust.cent = FALSE, palette = "jco", ggtheme = theme_classic())
```

